{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05_Webcam_Demo.ipynb\n",
    "### Real-time Facial Emotion Recognition Demo (Webcam)\n",
    "This notebook demonstrates running the webcam demo locally. It uses MTCNN for face detection and a trained Keras model for emotion classification. For best results run this notebook in a local environment (not cloud notebook) where a webcam is available.\n",
    "If running inside Jupyter, the video window will open via OpenCV (`cv2.imshow`). Press **q** in the video window to quit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mtcnn\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl.metadata (19 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting pretty_midi\n",
      "  Downloading pretty_midi-0.2.11.tar.gz (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (2.0.2)\n",
      "Collecting keras>=2.0.0 (from mtcnn)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-2.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp39-cp39-macosx_10_9_universal2.whl.metadata (8.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.4-cp39-cp39-macosx_10_9_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mido>=1.1.16 (from pretty_midi)\n",
      "  Downloading mido-1.3.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: importlib_resources in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from pretty_midi) (6.5.2)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=2.0.0->mtcnn)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=2.0.0->mtcnn)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=2.0.0->mtcnn)\n",
      "  Downloading optree-0.17.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.20.0->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.20.0->tensorflow) (3.23.0)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markupsafe-3.0.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=2.0.0->mtcnn)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from rich->keras>=2.0.0->mtcnn) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->mtcnn)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-macosx_13_0_arm64.whl (37.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m  \u001b[33m0:00:11\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.20.0-cp39-cp39-macosx_12_0_arm64.whl (200.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.4/200.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m  \u001b[33m0:01:04\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.76.0-cp39-cp39-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached ml_dtypes-0.5.3-cp39-cp39-macosx_10_9_universal2.whl (663 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp39-cp39-macosx_10_9_universal2.whl (209 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.14.0-cp39-cp39-macosx_11_0_arm64.whl (2.8 MB)\n",
      "Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading mido-1.3.3-py3-none-any.whl (54 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.33.0-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading markupsafe-3.0.3-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Downloading wrapt-2.0.0-cp39-cp39-macosx_11_0_arm64.whl (61 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.17.0-cp39-cp39-macosx_11_0_arm64.whl (337 kB)\n",
      "Using cached rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: pretty_midi\n",
      "  Building wheel for pretty_midi (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretty_midi: filename=pretty_midi-0.2.11-py3-none-any.whl size=5595978 sha256=47f21020dac5a40129d5e5960bd3ba5fbd3ce9bee42a01300124cb3109468c2f\n",
      "  Stored in directory: /Users/utsanjan/Library/Caches/pip/wheels/37/f9/a7/8ced3ffec1f7d4ec06325b115b86bf8ccc64483ecfd0673554\n",
      "Successfully built pretty_midi\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, urllib3, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, opencv-python, ml_dtypes, mido, mdurl, MarkupSafe, idna, h5py, grpcio, google_pasta, gast, charset_normalizer, certifi, absl-py, werkzeug, requests, pretty_midi, markdown-it-py, markdown, astunparse, tensorboard, rich, keras, tensorflow, mtcnn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35/35\u001b[0m [mtcnn]m33/35\u001b[0m [tensorflow]]]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 absl-py-2.3.1 astunparse-1.6.3 certifi-2025.10.5 charset_normalizer-3.4.4 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.14.0 idna-3.11 keras-3.10.0 libclang-18.1.1 markdown-3.9 markdown-it-py-3.0.0 mdurl-0.1.2 mido-1.3.3 ml_dtypes-0.5.3 mtcnn-0.1.1 namex-0.1.0 opencv-python-4.12.0.88 opt_einsum-3.4.0 optree-0.17.0 pretty_midi-0.2.11 protobuf-6.33.0 requests-2.32.5 rich-14.2.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run once in the environment)\n",
    "!pip install mtcnn opencv-python tensorflow pretty_midi numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from datetime import datetime\n",
    "print('OpenCV version:', cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters - edit as needed\n",
    "MODEL_PATH = '../models/mobilenet_emotion.h5'   # path to your trained model\n",
    "DATA_DIR = '../data/cropped_faces'              # used to infer labels (train subfolder names)\n",
    "INPUT_SIZE = 224                             # model input size\n",
    "CAMERA_INDEX = 0                             # change if you have multiple cameras\n",
    "GENERATE_MIDI = False                         # set True to save MIDI when emotion changes\n",
    "MIDI_OUT_DIR = 'outputs/generated_music'\n",
    "os.makedirs(MIDI_OUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Train dir not found: ../data/cropped_faces/train",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(train_dir) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, d))])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n\u001b[0;32m----> 7\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_labels_from_train_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabels:\u001b[39m\u001b[38;5;124m'\u001b[39m, labels)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mget_labels_from_train_dir\u001b[0;34m(train_dir)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_labels_from_train_dir\u001b[39m(train_dir):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(train_dir):\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain dir not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(train_dir) \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, d))])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "\u001b[0;31mValueError\u001b[0m: Train dir not found: ../data/cropped_faces/train"
     ]
    }
   ],
   "source": [
    "def get_labels_from_train_dir(train_dir):\n",
    "    if not os.path.isdir(train_dir):\n",
    "        raise ValueError(f\"Train dir not found: {train_dir}\")\n",
    "    labels = sorted([d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))])\n",
    "    return labels\n",
    "\n",
    "labels = get_labels_from_train_dir(os.path.join(DATA_DIR, 'train'))\n",
    "print('Labels:', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model...')\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print('Model loaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = MTCNN()\n",
    "cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "prev_label = None\n",
    "print('Starting webcam. Press q in the video window to quit.')\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Failed to read from camera. Exiting.')\n",
    "            break\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = detector.detect_faces(rgb)\n",
    "        for det in detections:\n",
    "            x, y, w, h = det['box']\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            try:\n",
    "                face_resized = cv2.resize(face, (INPUT_SIZE, INPUT_SIZE))\n",
    "            except Exception:\n",
    "                continue\n",
    "            face_arr = face_resized.astype('float32') / 255.0\n",
    "            face_arr = np.expand_dims(face_arr, axis=0)\n",
    "            preds = model.predict(face_arr, verbose=0)\n",
    "            idx = int(np.argmax(preds))\n",
    "            prob = float(np.max(preds))\n",
    "            label = labels[idx] if idx < len(labels) else str(idx)\n",
    "\n",
    "            color = (0, 255, 0) if prob > 0.6 else (0, 200, 200)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {prob:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
    "\n",
    "            # Optional: save MIDI when emotion changes (if you enabled generation and have emotion_to_midi)\n",
    "            if GENERATE_MIDI and label != prev_label and prob > 0.6:\n",
    "                try:\n",
    "                    from scripts.emotion_to_midi import generate_melody\n",
    "                    midi_path = os.path.join(MIDI_OUT_DIR, f\"{label}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mid\")\n",
    "                    generate_melody(label, length=16, out_path=midi_path)\n",
    "                    print('Saved MIDI:', midi_path)\n",
    "                except Exception as e:\n",
    "                    print('MIDI generation failed:', e)\n",
    "                prev_label = label\n",
    "\n",
    "        cv2.imshow('FER Webcam Demo', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print('Webcam demo ended.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "- If the webcam window doesn't open in your environment, run `python scripts/webcam_demo.py` from a terminal instead of the notebook.\n",
    "- If MTCNN is slow, consider using OpenCV Haar cascade for face detection as a faster (but less accurate) alternative.\n",
    "- If model loading fails, ensure `MODEL_PATH` points to a valid Keras `.h5` or SavedModel.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
