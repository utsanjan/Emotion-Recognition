{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_Train_Transfer.ipynb\n",
    "### Transfer Learning (MobileNetV2 / ResNet50) on FER2013\n",
    "This notebook trains a transfer-learning model on preprocessed images (224Ã—224 RGB) and saves the best checkpoint.\n",
    "Expected data layout: `data/cropped_faces/train/<class>/...` and `data/cropped_faces/val/<class>/...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install tensorflow opencv-python matplotlib numpy pandas tqdm seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (edit as needed)\n",
    "DATA_DIR = 'data/cropped_faces'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR = os.path.join(DATA_DIR, 'val')\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "BACKBONE = 'mobilenet'  # options: 'mobilenet' or 'resnet50'\n",
    "OUT_MODEL = 'models/mobilenet_emotion.h5'\n",
    "UNFREEZE_LAYERS = 30  # number of layers from base to keep trainable when fine-tuning\n",
    "os.makedirs('models', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "NUM_CLASSES = train_gen.num_classes\n",
    "CLASS_INDICES = train_gen.class_indices\n",
    "print('Classes:', CLASS_INDICES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model function\n",
    "def build_model(backbone='mobilenet', input_shape=(224,224,3), num_classes=7, dropout=0.5):\n",
    "    if backbone == 'mobilenet':\n",
    "        base = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif backbone == 'resnet50':\n",
    "        base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError('Unsupported backbone')\n",
    "    base.trainable = False\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = base(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model, base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model, base = build_model(backbone=BACKBONE, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), num_classes=NUM_CLASSES)\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(OUT_MODEL, save_best_only=True, monitor='val_loss'),\n",
    "    EarlyStopping(patience=7, restore_best_weights=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(factor=0.5, patience=3, monitor='val_loss')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (feature extraction)\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune: unfreeze last UNFREEZE_LAYERS of base\n",
    "base.trainable = True\n",
    "if UNFREEZE_LAYERS > 0:\n",
    "    for layer in base.layers[:-UNFREEZE_LAYERS]:\n",
    "        layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "ft_history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "model.save(OUT_MODEL)\n",
    "print('Saved model to', OUT_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves (combined)\n",
    "def plot_hist(hist, label_prefix=''):\n",
    "    h = hist.history\n",
    "    return h.get('loss', []), h.get('val_loss', []), h.get('accuracy', []), h.get('val_accuracy', [])\n",
    "\n",
    "loss1, vloss1, acc1, vacc1 = plot_hist(history)\n",
    "loss2, vloss2, acc2, vacc2 = plot_hist(ft_history)\n",
    "\n",
    "loss = loss1 + loss2\n",
    "vloss = vloss1 + vloss2\n",
    "acc = acc1 + acc2\n",
    "vacc = vacc1 + vacc2\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(loss, label='train_loss')\n",
    "plt.plot(vloss, label='val_loss')\n",
    "plt.legend(); plt.title('Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(acc, label='train_acc')\n",
    "plt.plot(vacc, label='val_acc')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick evaluation and confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "val_steps = val_gen.samples // val_gen.batch_size\n",
    "preds = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_gen.classes\n",
    "labels = list(val_gen.class_indices.keys())\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- If you have limited GPU, reduce `BATCH_SIZE` and `EPOCHS`.\n",
    "- Use class weights for imbalanced classes (compute from `train_gen.class_indices`).\n",
    "- Consider using `tf.data` pipelines for faster loading on large datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}