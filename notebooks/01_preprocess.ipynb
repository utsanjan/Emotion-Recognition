{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_Preprocess.ipynb\n",
    "### Facial Emotion Recognition — Data Preprocessing\n",
    "This notebook loads the FER2013 dataset (`fer2013.csv`), converts pixel strings to images, optionally applies face detection (MTCNN), and saves them in a structured `train/val` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (0.1.1)\n",
      "Requirement already satisfied: opencv-python in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: pandas in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: tqdm in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (4.67.1)\n",
      "Requirement already satisfied: pillow in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (11.3.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from mtcnn) (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (2.3.1)\n",
      "Requirement already satisfied: rich in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (14.2.0)\n",
      "Requirement already satisfied: namex in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (0.1.0)\n",
      "Requirement already satisfied: h5py in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (3.14.0)\n",
      "Requirement already satisfied: optree in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (0.17.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (0.5.3)\n",
      "Requirement already satisfied: packaging in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from keras>=2.0.0->mtcnn) (25.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from optree->keras>=2.0.0->mtcnn) (4.15.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from rich->keras>=2.0.0->mtcnn) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from rich->keras>=2.0.0->mtcnn) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/utsanjan/.pyenv/versions/3.9.19/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->mtcnn) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install mtcnn opencv-python pandas numpy tqdm pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "DATA_PATH = '../data/fer2013.csv'\n",
    "OUTPUT_DIR = '../data/cropped_faces'\n",
    "TARGET_SIZE = 224\n",
    "USE_MTCNN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (35887, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df = df[df['pixels'].notnull()]\n",
    "print('Dataset shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixels_to_image(pixels_str):\n",
    "    arr = np.fromstring(pixels_str, dtype=int, sep=' ')\n",
    "    img = arr.reshape(48, 48).astype('uint8')\n",
    "    return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "detector = MTCNN() if USE_MTCNN else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop(img, target_size=224):\n",
    "    if detector is None:\n",
    "        return cv2.resize(img, (target_size, target_size))\n",
    "    results = detector.detect_faces(img)\n",
    "    if not results:\n",
    "        return cv2.resize(img, (target_size, target_size))\n",
    "    x, y, w, h = results[0]['box']\n",
    "    x, y = max(0, x), max(0, y)\n",
    "    face = img[y:y + h, x:x + w]\n",
    "    return cv2.resize(face, (target_size, target_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35887/35887 [00:08<00:00, 4277.92it/s]\n"
     ]
    }
   ],
   "source": [
    "X_paths, y_labels = [], []\n",
    "temp_dir = os.path.join(OUTPUT_DIR, 'temp_raw')\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    img = pixels_to_image(row['pixels'])\n",
    "    label = str(int(row['emotion']))\n",
    "    out_path = os.path.join(temp_dir, f'{idx}_{label}.jpg')\n",
    "    Image.fromarray(img).save(out_path)\n",
    "    X_paths.append(out_path)\n",
    "    y_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_paths, y_labels, test_size=0.15, stratify=y_labels, random_state=42)\n",
    "splits = [('train', X_train, y_train), ('val', X_val, y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_name, X_split, y_split in splits:\n",
    "    for img_path, label in tqdm(list(zip(X_split, y_split)), desc=f'Processing {split_name}'):\n",
    "        img = cv2.imread(img_path)\n",
    "        cropped = detect_and_crop(img, TARGET_SIZE)\n",
    "        out_folder = os.path.join(OUTPUT_DIR, split_name, label)\n",
    "        os.makedirs(out_folder, exist_ok=True)\n",
    "        out_file = os.path.join(out_folder, os.path.basename(img_path))\n",
    "        cv2.imwrite(out_file, cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preprocessing completed successfully!')\n",
    "print('Saved structure:')\n",
    "!tree data/cropped_faces -L 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.19",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
