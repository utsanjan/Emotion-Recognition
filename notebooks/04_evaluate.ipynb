{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_Evaluate.ipynb\n",
    "### Evaluation notebook\n",
    "Loads a trained model, runs predictions on the validation/test set, produces a classification report, confusion matrix, and saves figures to `outputs/figures/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install tensorflow matplotlib seaborn scikit-learn opencv-python tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters - edit if needed\n",
    "MODEL_PATH = 'models/mobilenet_emotion.h5'  # change to your model path\n",
    "VAL_DIR = 'data/cropped_faces/val'          # validation folder (flow_from_directory)\n",
    "INPUT_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "OUT_DIR = 'outputs/figures'\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading model...')\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Preparing validation generator...')\n",
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "labels = list(val_gen.class_indices.keys())\n",
    "print('Classes:', labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting on validation set...')\n",
    "steps = int(np.ceil(val_gen.samples / val_gen.batch_size))\n",
    "preds = model.predict(val_gen, steps=steps, verbose=1)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_gen.classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nClassification Report:')\n",
    "report = classification_report(y_true, y_pred, target_names=labels, digits=4)\n",
    "print(report)\n",
    "with open(os.path.join(OUT_DIR, 'classification_report.txt'), 'w') as f:\n",
    "    f.write(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Computing confusion matrix...')\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_path = os.path.join(OUT_DIR, 'confusion_matrix.png')\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_path, dpi=300)\n",
    "plt.show()\n",
    "print(f'Saved confusion matrix to: {cm_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.sum(y_pred == y_true) / len(y_true)\n",
    "print(f'Validation Accuracy: {acc*100:.2f}%')\n",
    "with open(os.path.join(OUT_DIR, 'summary.txt'), 'w') as f:\n",
    "    f.write(f'Validation Accuracy: {acc*100:.2f}%\\n')\n",
    "    f.write('Confusion matrix saved to: ' + cm_path + '\\n')\n",
    "    f.write('Classification report saved to: ' + os.path.join(OUT_DIR, 'classification_report.txt') + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Per-class precision/recall bar chart\n",
    "This visualizes precision and recall for each class using the saved classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = precision_score(y_true, y_pred, average=None, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average=None, zero_division=0)\n",
    "x = np.arange(len(labels))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(x - 0.15, precision, width=0.3, label='Precision')\n",
    "plt.bar(x + 0.15, recall, width=0.3, label='Recall')\n",
    "plt.xticks(x, labels, rotation=45)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.title('Per-class Precision and Recall')\n",
    "pr_path = os.path.join(OUT_DIR, 'precision_recall.png')\n",
    "plt.tight_layout()\n",
    "plt.savefig(pr_path, dpi=300)\n",
    "plt.show()\n",
    "print(f'Saved precision/recall plot to: {pr_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}