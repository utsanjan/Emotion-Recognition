# ğŸ­ Facial Emotion Recognition - Capstone Project
[![Buy Me A Coffee](https://img.shields.io/open-vsx/stars/redhat/java?color=D8B024&label=buy%20me%20a%20coffee&style=flat)](https://www.buymeacoffee.com/utsanjan)â€ â€
[![](https://dcbadge.limes.pink/api/server/uavTPkr?style=flat)](https://discord.gg/ZuuWJm7MR3)â€ â€ 
[![](https://img.shields.io/github/license/utsanjan/Emotion-Recognition?logoColor=red&style=flat)](https://github.com/utsanjan/Emotion-Recognition/blob/main/LICENSE)â€ â€
[![](https://img.shields.io/github/languages/count/utsanjan/Emotion-Recognition?style=flat)](https://github.com/utsanjan/Emotion-Recognition/search?l=shell)â€ â€
[![](https://img.shields.io/github/languages/top/utsanjan/Emotion-Recognition?color=light%20green&style=flat)](https://github.com/utsanjan/Emotion-Recognition)â€ â€

This project provides a comprehensive end-to-end solution for detecting and classifying human emotions - such as happiness, sadness, and anger - based on facial expressions. By leveraging deep learning and computer vision techniques, this repository delivers a state-of-the-art implementation of Facial Emotion Recognition (FER). This repository implements **Facial Emotion Recognition (FER)** using:
- **Convolutional Neural Networks (CNNs)** for baseline learning.
- **Transfer Learning** with **MobileNetV2** and **ResNet50** for improved accuracy.
- **MTCNN** for face detection & cropping.
- **DCGAN** for generating synthetic faces.
- Optional **MIDI music generation** based on predicted emotions.

## ğŸ§© Features
âœ… Train baseline CNN on FER2013 dataset (48Ã—48 grayscale).  
âœ… Fine-tune transfer-learning model (MobileNetV2/ResNet50).  
âœ… Real-time webcam emotion detection.  
âœ… Evaluate model using confusion matrix & classification report.  
âœ… Generate synthetic faces via DCGAN.  
âœ… Create emotion-based melodies (MIDI).

## ğŸ“‚ Project Structure
```
FER-Capstone/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ fer2013.csv              # Original dataset (from Kaggle)
â”‚   â”œâ”€â”€ cropped_faces/           # Preprocessed dataset
â”‚   â”‚   â”œâ”€â”€ train/<class>/
â”‚   â”‚   â””â”€â”€ val/<class>/
â”‚   â””â”€â”€ sample_images/           # Optional test images
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_cnn.h5
â”‚   â””â”€â”€ mobilenet_emotion.h5
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                 # Confusion matrices, plots
â”‚   â”œâ”€â”€ generated_faces/         # DCGAN samples
â”‚   â””â”€â”€ generated_music/         # MIDI outputs
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_baseline.py
â”‚   â”œâ”€â”€ train_transfer.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ webcam_demo.py
â”‚   â”œâ”€â”€ dcgan.py
â”‚   â””â”€â”€ emotion_to_midi.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ mtcnn_face_crop.py
â”‚   â””â”€â”€ data_loader.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_preprocess.ipynb
â”‚   â”œâ”€â”€ 02_train_baseline.ipynb
â”‚   â”œâ”€â”€ 03_train_transfer.ipynb
â”‚   â”œâ”€â”€ 04_evaluate.ipynb
â”‚   â””â”€â”€ 05_webcam_demo.ipynb
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/<your-username>/FER-Capstone.git
cd FER-Capstone
```

### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Download dataset
Download FER2013 from Kaggle:  
[https://www.kaggle.com/datasets/nicolejyt/facialexpressionrecognition](https://www.kaggle.com/datasets/nicolejyt/facialexpressionrecognition)

Place it in:
```bash
data/fer2013.csv
```

## ğŸ§  Preprocessing
Convert FER CSV to cropped, normalized images:
```bash
python scripts/preprocess.py --csv data/fer2013.csv --out data/cropped_faces --target-size 224 --use-mtcnn
```

## ğŸ‹ï¸â€â™‚ï¸ Training

### Baseline CNN
```bash
python scripts/train_baseline.py --data data/cropped_faces --epochs 25 --batch 64
```

### Transfer Learning (MobileNetV2)
```bash
python scripts/train_transfer.py --data data/cropped_faces --arch mobilenet --epochs 30 --input-size 224
```

## ğŸ“Š Evaluation
Generate confusion matrix and classification report:
```bash
python scripts/evaluate.py --model models/mobilenet_emotion.h5 --data data/cropped_faces/val
```

## ğŸ¥ Real-Time Demo
Run live webcam emotion recognition:
```bash
python scripts/webcam_demo.py --model models/mobilenet_emotion.h5 --data-dir data/cropped_faces --input-size 224
```
Press `q` to quit webcam window.

## ğŸ§¬ Optional - DCGAN (Face Generation)
Train GAN to generate facial expressions:
```bash
python scripts/dcgan.py --data data/cropped_faces/train --out outputs/generated_faces --epochs 20000
```

## ğŸµ Optional - Emotion-to-Music
Generate MIDI melody for any emotion:
```bash
python scripts/emotion_to_midi.py --emotion Happy --out outputs/generated_music/happy.mid
```

## ğŸ§¾ Dataset References
- [FER2013 (Kaggle)](https://www.kaggle.com/datasets/nicolejyt/facialexpressionrecognition)
- [UTKFace Cropped Dataset (Hugging Face)](https://huggingface.co/datasets/UTKFace)

## ğŸ§ª Tech Stack
- Python 3.10+
- TensorFlow / Keras
- OpenCV
- MTCNN
- Matplotlib / Seaborn
- PrettyMIDI for audio generation

## ğŸ“ˆ Results (Example)
| Model              | Accuracy       | Notes                              |
|--------------------|----------------|------------------------------------|
| Baseline CNN       | ~65%           | Simple grayscale CNN               |
| MobileNetV2 (TL)   | ~73â€“80%        | Transfer learning + 224px RGB      |
| ResNet50 (TL)      | ~78â€“82%        | Higher accuracy, more compute      |

## ğŸ¤ Acknowledgements
- FER2013 dataset by Pierre-Luc Carrier & Aaron Courville
- Preprocessing logic inspired by [GSNCodes (GitHub)](https://github.com/GSNCodes)
- Keras DCGAN example - Â© Keras Team

## ğŸ“œ License
This project is licensed under the MIT License - see LICENSE file for details.

## ğŸ“¬ Contact
- Questions? Reach out on [Instagram](https://www.instagram.com/utsanjan/)
- Explore more on my [YouTube Channel](https://www.youtube.com/DopeSatan)
- Join the [Discord Community](https://discord.gg/ZuuWJm7MR3)